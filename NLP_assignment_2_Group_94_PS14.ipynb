{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "c403bc6cbf9f4c79836195206904e2c6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_e65977d3b3f149f78191ff6aad3fc98f",
              "IPY_MODEL_b8630d29e0d34605be97bf0ea9d27489",
              "IPY_MODEL_fc13259dabde442689cc10e7b6611b8e"
            ],
            "layout": "IPY_MODEL_1341f4f0f8c94cbc9fd54ea16ca52536"
          }
        },
        "e65977d3b3f149f78191ff6aad3fc98f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_c836285e7fb647d5bce7a30402b38305",
            "placeholder": "​",
            "style": "IPY_MODEL_ce9cfde5d9854046b03ac74ff2d7a73b",
            "value": "Loading weights: 100%"
          }
        },
        "b8630d29e0d34605be97bf0ea9d27489": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_30b1d94d653146e2a1d19b3cef7f2cde",
            "max": 103,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_aaba6848078245dcb3d449d4c0643a03",
            "value": 103
          }
        },
        "fc13259dabde442689cc10e7b6611b8e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_476e2b67b9b74045b5689e087070a0b0",
            "placeholder": "​",
            "style": "IPY_MODEL_fff32956a7254c0cbcf2eabd7efb9026",
            "value": " 103/103 [00:00&lt;00:00, 414.72it/s, Materializing param=pooler.dense.weight]"
          }
        },
        "1341f4f0f8c94cbc9fd54ea16ca52536": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c836285e7fb647d5bce7a30402b38305": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ce9cfde5d9854046b03ac74ff2d7a73b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "30b1d94d653146e2a1d19b3cef7f2cde": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "aaba6848078245dcb3d449d4c0643a03": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "476e2b67b9b74045b5689e087070a0b0": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "fff32956a7254c0cbcf2eabd7efb9026": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "3fb107166c104ee9a304e04603c1158e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_56e385b397f8424d829198cb4fe5c5af",
              "IPY_MODEL_bea0da0471fd480cae084fcf58594930",
              "IPY_MODEL_7f92e645f5284d2094810265ceca6c29"
            ],
            "layout": "IPY_MODEL_a81c9483fffb47eeb0ac3c72a52385b4"
          }
        },
        "56e385b397f8424d829198cb4fe5c5af": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_d2327c80d61c44c5a2ba6ea27ebad157",
            "placeholder": "​",
            "style": "IPY_MODEL_74a21c8d6b104fd2a15da64ea3e6859b",
            "value": "Batches: 100%"
          }
        },
        "bea0da0471fd480cae084fcf58594930": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_b526c89223a942dab103ee35a039425b",
            "max": 3,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_0c71e2ccab6e44a595eaf2369da58faf",
            "value": 3
          }
        },
        "7f92e645f5284d2094810265ceca6c29": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_633b83d10e5343388cd6439f0d165798",
            "placeholder": "​",
            "style": "IPY_MODEL_b584484336ea47ddbbdfc62be4f264ef",
            "value": " 3/3 [00:00&lt;00:00,  5.08it/s]"
          }
        },
        "a81c9483fffb47eeb0ac3c72a52385b4": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d2327c80d61c44c5a2ba6ea27ebad157": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "74a21c8d6b104fd2a15da64ea3e6859b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "b526c89223a942dab103ee35a039425b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "0c71e2ccab6e44a595eaf2369da58faf": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "633b83d10e5343388cd6439f0d165798": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b584484336ea47ddbbdfc62be4f264ef": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "eb0ffb8562124cb8a68f998f816ed911": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_1f96bee7e0ee4477a4a4cda04eb03553",
              "IPY_MODEL_780e2da6f75543dfb2948f2cf2eac595",
              "IPY_MODEL_887a1c2b54ac41c29a391f68e57e7984"
            ],
            "layout": "IPY_MODEL_54bf26090ab9414780728a99a9022dbc"
          }
        },
        "1f96bee7e0ee4477a4a4cda04eb03553": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_62989f29cca34f41b6802453098d23f1",
            "placeholder": "​",
            "style": "IPY_MODEL_aa4a2b7666d6455883ac48c1d91be1b3",
            "value": "Loading weights: 100%"
          }
        },
        "780e2da6f75543dfb2948f2cf2eac595": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_cee539f0f9854525a4e3c4618a243d2f",
            "max": 282,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_d4a5eebce9d34d18955fb52c85040ef3",
            "value": 282
          }
        },
        "887a1c2b54ac41c29a391f68e57e7984": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_08c6c0a4abd04795b1c56128a67005b3",
            "placeholder": "​",
            "style": "IPY_MODEL_87fd69d417c244c29190aefe5e0a6f57",
            "value": " 282/282 [00:03&lt;00:00, 81.14it/s, Materializing param=shared.weight]"
          }
        },
        "54bf26090ab9414780728a99a9022dbc": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "62989f29cca34f41b6802453098d23f1": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "aa4a2b7666d6455883ac48c1d91be1b3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "cee539f0f9854525a4e3c4618a243d2f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d4a5eebce9d34d18955fb52c85040ef3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "08c6c0a4abd04795b1c56128a67005b3": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "87fd69d417c244c29190aefe5e0a6f57": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "## NLP Assignment 2 PS 14\n",
        "## Group 94\n",
        "\n",
        "| Sr No | Name               | BITS ID        | Contribution |\n",
        "|------:|--------------------|----------------|--------------|\n",
        "| 1     | Vinay Bora         | 2024ad05062    | 100%         |\n",
        "| 2     | Thiyagesh D        | 2024ad05395    | 100%         |\n",
        "| 3     | Sajal Jain         | 2024ac05874    | 100%         |\n",
        "| 4     | Pavithra R         | 2024ad05121    | 100%         |\n",
        "| 5     | Gaikwad Priyanka P | 2024ad05316    | 100%         |\n"
      ],
      "metadata": {
        "id": "9n2yfWD_335r"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#install all library\n",
        "# !pip install -U sentence-transformers\n",
        "# !pip install chromadb\n",
        "# !pip install -U ragas\n",
        "# !pip install -U langchain-community\n",
        "# !pip install transformers accelerate bitsandbytes\n",
        "# !pip install -U ragas transformers accelerate sentence-transformers langchain-community\n"
      ],
      "metadata": {
        "id": "vH1a_2ab6Auu"
      },
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 1. The Ingestion Pipeline"
      ],
      "metadata": {
        "id": "DiVcZnr4-G5y"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "id": "VUNE3Ouw993-",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "18f47a1f-86fe-452c-86a5-d5977c0807be"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "b'\\xef\\xbb\\xbfThe Project Gutenberg eBook of Pioneer Saturn Encounter\\r\\n    \\r\\nThis ebook is for the use of anyon'\n"
          ]
        }
      ],
      "source": [
        "#Read data from source\n",
        "import requests\n",
        "file_url=\"https://www.gutenberg.org/ebooks/55695.txt.utf-8\"\n",
        "content=requests.get(file_url).content\n",
        "print(content[:100])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2a8d06ce"
      },
      "source": [
        "### Chunking Strategy"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "53d7cceb",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "172cfe5c-8263-473b-e90d-01fa8b019561"
      },
      "source": [
        "#fixed size chunking\n",
        "chunk_size = 1000\n",
        "overlap_size = 200\n",
        "\n",
        "chunks = []\n",
        "for i in range(0, len(content), chunk_size - overlap_size):\n",
        "    chunk = content[i : i + chunk_size]\n",
        "    chunks.append(chunk)\n",
        "\n",
        "# Display the first few chunks and their lengths\n",
        "for i, chunk in enumerate(chunks[:3]):\n",
        "    print(f\"Chunk {i+1} (length {len(chunk)}):\\n{chunk[:200]}\\n...\")"
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Chunk 1 (length 1000):\n",
            "b'\\xef\\xbb\\xbfThe Project Gutenberg eBook of Pioneer Saturn Encounter\\r\\n    \\r\\nThis ebook is for the use of anyone anywhere in the United States and\\r\\nmost other parts of the world at no cost and with almost no res'\n",
            "...\n",
            "Chunk 2 (length 1000):\n",
            "b'line Distributed\\r\\n        Proofreading Team at http://www.pgdp.net\\r\\n\\r\\n\\r\\n*** START OF THE PROJECT GUTENBERG EBOOK PIONEER SATURN ENCOUNTER ***\\r\\n\\r\\n                        PIONEER SATURN ENCOUNTER\\r\\n\\r\\n\\r\\n '\n",
            "...\n",
            "Chunk 3 (length 1000):\n",
            "b'd 11 spacecraft, launched in 1972 and 1973,\\r\\nrespectively, were well named: they made the first crossings of the\\r\\nasteroid belt and were the first to encounter Jupiter and its intense\\r\\nradiation belts'\n",
            "...\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6fa18b56",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "46865545-e0ef-4518-e81e-b4f281e5c68c"
      },
      "source": [
        "print(f\"Total number of chunks: {len(chunks)}\")"
      ],
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Total number of chunks: 72\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "d106e7c3"
      },
      "source": [
        "# Vectorization"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "46f4b895",
        "collapsed": true,
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 188,
          "referenced_widgets": [
            "c403bc6cbf9f4c79836195206904e2c6",
            "e65977d3b3f149f78191ff6aad3fc98f",
            "b8630d29e0d34605be97bf0ea9d27489",
            "fc13259dabde442689cc10e7b6611b8e",
            "1341f4f0f8c94cbc9fd54ea16ca52536",
            "c836285e7fb647d5bce7a30402b38305",
            "ce9cfde5d9854046b03ac74ff2d7a73b",
            "30b1d94d653146e2a1d19b3cef7f2cde",
            "aaba6848078245dcb3d449d4c0643a03",
            "476e2b67b9b74045b5689e087070a0b0",
            "fff32956a7254c0cbcf2eabd7efb9026"
          ]
        },
        "outputId": "17b09be8-cc2d-40f3-a2cb-515765b52dc0"
      },
      "source": [
        "# Load a pre-trained embedding model\n",
        "# !pip install -U sentence-transformers\n",
        "from sentence_transformers import SentenceTransformer\n",
        "\n",
        "model_name = 'all-MiniLM-L6-v2'\n",
        "embedding_model = SentenceTransformer(model_name)\n",
        "\n",
        "print(f\"Embedding model '{model_name}' loaded successfully.\")"
      ],
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Loading weights:   0%|          | 0/103 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "c403bc6cbf9f4c79836195206904e2c6"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[1mBertModel LOAD REPORT\u001b[0m from: sentence-transformers/all-MiniLM-L6-v2\n",
            "Key                     | Status     |  | \n",
            "------------------------+------------+--+-\n",
            "embeddings.position_ids | UNEXPECTED |  | \n",
            "\n",
            "\u001b[3mNotes:\n",
            "- UNEXPECTED\u001b[3m\t:can be ignored when loading from different task/architecture; not ok if you expect identical arch.\u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Embedding model 'all-MiniLM-L6-v2' loaded successfully.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4699c132",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 84,
          "referenced_widgets": [
            "3fb107166c104ee9a304e04603c1158e",
            "56e385b397f8424d829198cb4fe5c5af",
            "bea0da0471fd480cae084fcf58594930",
            "7f92e645f5284d2094810265ceca6c29",
            "a81c9483fffb47eeb0ac3c72a52385b4",
            "d2327c80d61c44c5a2ba6ea27ebad157",
            "74a21c8d6b104fd2a15da64ea3e6859b",
            "b526c89223a942dab103ee35a039425b",
            "0c71e2ccab6e44a595eaf2369da58faf",
            "633b83d10e5343388cd6439f0d165798",
            "b584484336ea47ddbbdfc62be4f264ef"
          ]
        },
        "outputId": "e1a1bd8e-4568-45d6-fdf3-a12c9799b6e7"
      },
      "source": [
        "# Generate embeddings for the chunks\n",
        "# The SentenceTransformer expects strings, so decode the byte chunks\n",
        "chunk_strings = [chunk.decode('utf-8', errors='ignore') for chunk in chunks]\n",
        "embeddings = embedding_model.encode(chunk_strings, show_progress_bar=True)\n",
        "\n",
        "print(f\"Generated {len(embeddings)} embeddings, each with dimension {embeddings.shape[1]}.\")\n",
        "print(f\"First embedding (first 5 values): {embeddings[0][:5]}\")"
      ],
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Batches:   0%|          | 0/3 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "3fb107166c104ee9a304e04603c1158e"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Generated 72 embeddings, each with dimension 384.\n",
            "First embedding (first 5 values): [-0.05332715 -0.04049236  0.06842367 -0.00429583  0.02655271]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "e6def4c9"
      },
      "source": [
        "# Storage"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9598b4c8",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e4ebaf08-2823-4f17-c140-6e9c0d12104e"
      },
      "source": [
        "# Install chromadb\n",
        "# !pip install chromadb\n",
        "\n",
        "import chromadb\n",
        "\n",
        "# Initialize an in-memory ChromaDB client\n",
        "client = chromadb.Client()\n",
        "\n",
        "# Create a collection\n",
        "collection_name = \"pioneer_saturn_chunks\"\n",
        "# Check if collection already exists to prevent errors on re-execution\n",
        "if collection_name in [col.name for col in client.list_collections()]:\n",
        "    client.delete_collection(name=collection_name)\n",
        "collection = client.create_collection(name=collection_name,configuration={\n",
        "        \"hnsw\": {\n",
        "            \"space\": \"cosine\"\n",
        "        }\n",
        "    }, metadata={\"hnsw:space\": \"cosine\"})\n",
        "\n",
        "# Prepare data for ChromaDB\n",
        "# ChromaDB expects string IDs, so we'll use a simple index as ID\n",
        "ids = [f\"chunk_{i}\" for i in range(len(chunk_strings))]\n",
        "\n",
        "# Add the documents and embeddings to the collection\n",
        "collection.add(\n",
        "    documents=chunk_strings,\n",
        "    embeddings=embeddings.tolist(), # Convert numpy array to list for ChromaDB\n",
        "    ids=ids\n",
        ")\n",
        "\n",
        "print(f\"Successfully created ChromaDB collection '{collection_name}' with {collection.count()} documents.\")"
      ],
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Successfully created ChromaDB collection 'pioneer_saturn_chunks' with 72 documents.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 2. The Retrieval Engine"
      ],
      "metadata": {
        "id": "IYNal7WLBir-"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8b6a2de3",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "da77cc95-1952-4977-ffef-9947ad4d7517"
      },
      "source": [
        "def semantic_search(query: str, k: int = 3) -> list:\n",
        "    # Embed the user query\n",
        "    query_embedding = embedding_model.encode([query]).tolist()\n",
        "\n",
        "    # Perform the similarity search\n",
        "    results = collection.query(\n",
        "        query_embeddings=query_embedding,\n",
        "        n_results=k,\n",
        "        include=['documents', 'distances']\n",
        "\n",
        "    )\n",
        "\n",
        "    # Extract and return relevant chunks\n",
        "    retrieved_chunks = []\n",
        "    if results and results['documents']:\n",
        "        for i in range(len(results['documents'][0])):\n",
        "            chunk_id = results['ids'][0][i]\n",
        "            document = results['documents'][0][i]\n",
        "            distance = results['distances'][0][i]\n",
        "            retrieved_chunks.append({\n",
        "                \"id\": chunk_id,\n",
        "                \"document\": document,\n",
        "                \"distance\": distance\n",
        "            })\n",
        "    return retrieved_chunks\n",
        "\n",
        "# Demonstrate the function with an example query\n",
        "query_example = \"What was the mission of Pioneer 11?\"\n",
        "relevant_chunks = semantic_search(query_example, k=3)\n",
        "\n",
        "print(f\"\\nQuery: '{query_example}'\")\n",
        "print(f\"\\nTop {len(relevant_chunks)} relevant chunks:\")\n",
        "for i, chunk in enumerate(relevant_chunks):\n",
        "    print(f\"\\n--- Chunk {i+1} (ID: {chunk['id']}, Distance: {chunk['distance']:.4f}) ---\")\n",
        "    print(chunk['document'][:100] + \"...\") # Print first 100 characters for brevity"
      ],
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Query: 'What was the mission of Pioneer 11?'\n",
            "\n",
            "Top 3 relevant chunks:\n",
            "\n",
            "--- Chunk 1 (ID: chunk_4, Distance: 0.3987) ---\n",
            "                          INTRODUCTION\r\n",
            "\r\n",
            "\r\n",
            "We have entered into a new era of space exploration. Mis...\n",
            "\n",
            "--- Chunk 2 (ID: chunk_2, Distance: 0.4432) ---\n",
            "d 11 spacecraft, launched in 1972 and 1973,\r\n",
            "respectively, were well named: they made the first cros...\n",
            "\n",
            "--- Chunk 3 (ID: chunk_6, Distance: 0.4946) ---\n",
            " penetrate deep below the Jovian clouds.\r\n",
            "\r\n",
            "In the coming years, each of these follow-on missions wi...\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 3. The Generation Component"
      ],
      "metadata": {
        "id": "fswqOwqgB_En"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Prompt Engineering"
      ],
      "metadata": {
        "id": "1CG_gBJyhvah"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def llm_prompt(context:str, question: str) -> str:\n",
        "  prompt = f\"\"\"You are a helpful assistant. Please answer the following question based ONLY on the provided context.\n",
        "  If the answer is not found in the context, please state that you don't have enough information.\n",
        "\n",
        "  Context:\n",
        "  {context}\n",
        "\n",
        "  Question:\n",
        "  {question}\n",
        "\n",
        "  Answer:\n",
        "  \"\"\"\n",
        "  return prompt\n"
      ],
      "metadata": {
        "id": "01ztU3DPht_H"
      },
      "execution_count": 32,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# LLM Integration"
      ],
      "metadata": {
        "id": "FTrgXyWyinxf"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ef25f08d"
      },
      "source": [
        "For this demonstration, we'll use a small model from HuggingFace to simulate the LLM generation step.\n",
        "Here we have integrated a small model `google/flan-t5-base` (a lightweight instruction-tuned model) to respond to the `final_prompt_for_llm`."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Install necessary libraries\n",
        "# !pip install transformers accelerate bitsandbytes\n",
        "\n",
        "import torch\n",
        "import os\n",
        "from transformers import AutoModelForCausalLM, AutoModelForSeq2SeqLM, AutoTokenizer\n",
        "from google.colab import userdata\n",
        "\n",
        "# Loading different, openly accessible model (Flan-T5-base or Mistral-7B)\n",
        "model_name = \"mistralai/Mistral-7B-Instruct-v0.2\"\n",
        "model_name = \"google/flan-t5-base\"\n",
        "\n",
        "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
        "tokenizer.pad_token = tokenizer.eos_token\n",
        "tokenizer.padding_side = \"left\"\n",
        "\n",
        "# Set pad token if it's not already set, common for causal models like Mistral\n",
        "if tokenizer.pad_token is None:\n",
        "    tokenizer.pad_token = tokenizer.eos_token\n",
        "\n",
        "# mistralai/Mistral-7B-Instruct-v0.2\n",
        "# model = AutoModelForCausalLM.from_pretrained(\n",
        "#     model_name,\n",
        "#     device_map=\"auto\",\n",
        "#     torch_dtype=torch.bfloat16\n",
        "# )\n",
        "model = AutoModelForSeq2SeqLM.from_pretrained(\n",
        "    model_name,\n",
        "    device_map=\"auto\",\n",
        "    torch_dtype=torch.bfloat16\n",
        ")\n",
        "# Ensure the model's generation config also has a pad_token_id set\n",
        "model.config.pad_token_id = tokenizer.eos_token_id\n",
        "\n",
        "print(f\"LLM model '{model_name}' loaded successfully.\")"
      ],
      "metadata": {
        "id": "QQtvcUdEimUM",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 104,
          "referenced_widgets": [
            "eb0ffb8562124cb8a68f998f816ed911",
            "1f96bee7e0ee4477a4a4cda04eb03553",
            "780e2da6f75543dfb2948f2cf2eac595",
            "887a1c2b54ac41c29a391f68e57e7984",
            "54bf26090ab9414780728a99a9022dbc",
            "62989f29cca34f41b6802453098d23f1",
            "aa4a2b7666d6455883ac48c1d91be1b3",
            "cee539f0f9854525a4e3c4618a243d2f",
            "d4a5eebce9d34d18955fb52c85040ef3",
            "08c6c0a4abd04795b1c56128a67005b3",
            "87fd69d417c244c29190aefe5e0a6f57"
          ]
        },
        "outputId": "eb960200-e87f-4814-cc6a-f5cb71cdcef5"
      },
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Loading weights:   0%|          | 0/282 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "eb0ffb8562124cb8a68f998f816ed911"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "The tied weights mapping and config for this model specifies to tie shared.weight to lm_head.weight, but both are present in the checkpoints, so we will NOT tie them. You should update the config with `tie_word_embeddings=False` to silence this warning\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "LLM model 'google/flan-t5-base' loaded successfully.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def generate_response(question: str) -> str:\n",
        "    # 1. Retrieve relevant chunks using the semantic search function\n",
        "\n",
        "    retrieved_info = semantic_search(question, k=3) # Retrieve top 3 chunks\n",
        "    print(\"Similarity Search Done!\")\n",
        "    # 2. Compile the retrieved chunks into a single context string\n",
        "    context_parts = [chunk['document'] for chunk in retrieved_info]\n",
        "    context = \"\\n\\n\".join(context_parts)\n",
        "    # 3. Format the prompt using the template and the gathered context\n",
        "    final_prompt_for_llm=llm_prompt(context, question)\n",
        "\n",
        "    # 4. Generate a response using the LLM\n",
        "    # Tokenize the input and ensure attention_mask is returned\n",
        "    tokenized_input = tokenizer(final_prompt_for_llm, return_tensors=\"pt\", return_attention_mask=True).to(model.device)\n",
        "\n",
        "    # print(\"Calling LLM:\")\n",
        "    output_ids = model.generate(\n",
        "        tokenized_input.input_ids,\n",
        "        attention_mask=tokenized_input.attention_mask, # Pass the attention_mask\n",
        "        max_new_tokens=200,\n",
        "        num_beams=5,\n",
        "        early_stopping=True,\n",
        "        pad_token_id=tokenizer.eos_token_id # Explicitly set pad_token_id for generation\n",
        "    )\n",
        "\n",
        "    # print(\"LLM call done!\")\n",
        "    # Decode and print the generated response\n",
        "    llm_response = tokenizer.decode(output_ids[0], skip_special_tokens=True)\n",
        "\n",
        "    answer_prefix = \"Answer:\"\n",
        "    if answer_prefix in llm_response:\n",
        "        actual_answer = llm_response.split(answer_prefix, 1)[1].strip()\n",
        "    else:\n",
        "        actual_answer = llm_response.strip()\n",
        "\n",
        "    return actual_answer, context"
      ],
      "metadata": {
        "id": "HrH2dZ-25DKF"
      },
      "execution_count": 34,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "question=\"Who authored the 'Pioneer Saturn Encounter' document?\"\n",
        "print(generate_response(question)[0])"
      ],
      "metadata": {
        "id": "bKtWxWM25GAs",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2df6c097-7e87-4d25-af7b-a577c2329fa0"
      },
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Token indices sequence length is longer than the specified maximum sequence length for this model (659 > 512). Running this sequence through the model will result in indexing errors\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Similarity Search Done!\n",
            "United States. National Aeronautics and Space Administration\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1749e00c",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f6d7d8b8-30ed-484f-e523-f7c1e7d83480"
      },
      "source": [
        "sample_queries = [\n",
        "    \"What is the primary objective of the Project Gutenberg eBook titled 'Pioneer Saturn Encounter'?\",\n",
        "    \"When was Pioneer 11 launched and what were its initial targets before reaching Saturn?\",\n",
        "    \"How did Jupiter's gravitational field influence Pioneer 11's trajectory towards Saturn?\",\n",
        "    \"What are some of the key scientific observations or data collected by Pioneer 11 at Saturn?\",\n",
        "    \"Who authored the 'Pioneer Saturn Encounter' document and when was it released?\"\n",
        "]\n",
        "\n",
        "print(f\"Generated {len(sample_queries)} sample queries:\")\n",
        "for i, query in enumerate(sample_queries):\n",
        "    print(f\"{i+1}. {query}\")"
      ],
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Generated 5 sample queries:\n",
            "1. What is the primary objective of the Project Gutenberg eBook titled 'Pioneer Saturn Encounter'?\n",
            "2. When was Pioneer 11 launched and what were its initial targets before reaching Saturn?\n",
            "3. How did Jupiter's gravitational field influence Pioneer 11's trajectory towards Saturn?\n",
            "4. What are some of the key scientific observations or data collected by Pioneer 11 at Saturn?\n",
            "5. Who authored the 'Pioneer Saturn Encounter' document and when was it released?\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "450ead34"
      },
      "source": [
        "## Process and Answer Queries\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "87bb487e",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d36099ea-8ab3-4766-c938-c093835d5900"
      },
      "source": [
        "print(\"\\n-----------------------------------------------------\")\n",
        "print(\"Demonstration of RAG process for all sample queries complete.\")\n",
        "for i, query in enumerate(sample_queries):\n",
        "    print(f\"\\n-----------------------------------------------------\\nProcessing Query {i+1}:\")\n",
        "    print(f\"Query: {query}\")\n",
        "\n",
        "    llm_response,context = generate_response(query)\n",
        "    print(f\"LLM's Answer: {llm_response}\")\n",
        "    print(f\"First 100 tokens of Context: {context[:100]}...\")\n",
        "\n",
        "\n"
      ],
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "-----------------------------------------------------\n",
            "Demonstration of RAG process for all sample queries complete.\n",
            "\n",
            "-----------------------------------------------------\n",
            "Processing Query 1:\n",
            "Query: What is the primary objective of the Project Gutenberg eBook titled 'Pioneer Saturn Encounter'?\n",
            "Similarity Search Done!\n",
            "LLM's Answer: free distribution of electronic works\n",
            "First 100 tokens of Context: ﻿The Project Gutenberg eBook of Pioneer Saturn Encounter\n",
            "    \n",
            "This ebook is for the use of anyone ...\n",
            "\n",
            "-----------------------------------------------------\n",
            "Processing Query 2:\n",
            "Query: When was Pioneer 11 launched and what were its initial targets before reaching Saturn?\n",
            "Similarity Search Done!\n",
            "LLM's Answer: April 5, 1973\n",
            "First 100 tokens of Context:  penetrate deep below the Jovian clouds.\n",
            "\n",
            "In the coming years, each of these follow-on missions wi...\n",
            "\n",
            "-----------------------------------------------------\n",
            "Processing Query 3:\n",
            "Query: How did Jupiter's gravitational field influence Pioneer 11's trajectory towards Saturn?\n",
            "Similarity Search Done!\n",
            "LLM's Answer: allowed it to recross the solar system to make the first flyby of Saturn\n",
            "First 100 tokens of Context:  penetrate deep below the Jovian clouds.\n",
            "\n",
            "In the coming years, each of these follow-on missions wi...\n",
            "\n",
            "-----------------------------------------------------\n",
            "Processing Query 4:\n",
            "Query: What are some of the key scientific observations or data collected by Pioneer 11 at Saturn?\n",
            "Similarity Search Done!\n",
            "LLM's Answer: measurements of its rings and several of its moons, including the largest moon, the planet-sized Titan\n",
            "First 100 tokens of Context: d 11 spacecraft, launched in 1972 and 1973,\n",
            "respectively, were well named: they made the first cros...\n",
            "\n",
            "-----------------------------------------------------\n",
            "Processing Query 5:\n",
            "Query: Who authored the 'Pioneer Saturn Encounter' document and when was it released?\n",
            "Similarity Search Done!\n",
            "LLM's Answer: United States. National Aeronautics and Space Administration\n",
            "First 100 tokens of Context: ﻿The Project Gutenberg eBook of Pioneer Saturn Encounter\n",
            "    \n",
            "This ebook is for the use of anyone ...\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 4. Evaluation\n"
      ],
      "metadata": {
        "id": "tY46OsGuzzqI"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "To ensure the reliability of the Retrieval-Augmented Generation (RAG) pipeline, both the Retriever and Generator must be evaluated independently and jointly.\n",
        "\n",
        "## 1. Retriever Evaluation — Contextual Precision\n",
        "Definition:\n",
        "Contextual Precision measures whether the retrieved chunks are actually relevant to the user’s query.\n",
        "\n",
        "Theoretical Approach:\n",
        "Create a small gold-standard dataset consisting of: User queries\n",
        "Expected relevant passages from the ebook\n",
        "Compare retrieved chunks with the ground truth.\n",
        "\n",
        "Metric:\n",
        "Contextual Precision = Number of Relevant Chunks Retrieved/Total Chunks Retrieved.\n",
        "For example, if 2 out of the top 3 retrieved chunks are relevant, precision = 0.67.\n",
        "\n",
        "Practical Implementation:\n",
        "Use Top-k Precision and optionally Recall@k.\n",
        "Manually label relevance for at least 10–20 queries.\n",
        "Automate evaluation using RAGAS context_precision metric.\n",
        "\n",
        "How this prevents hallucination:\n",
        "If irrelevant context is retrieved, the generator is more likely to fabricate answers. High contextual precision ensures the model receives only useful evidence.\n",
        "\n",
        "\n",
        "## 2. Generator Evaluation — Faithfulness\n",
        "\n",
        "Definition:\n",
        "Faithfulness measures whether the generated answer is strictly supported by the retrieved context and does not introduce external knowledge.\n",
        "\n",
        "Theoretical Approach:\n",
        "Faithfulness can be framed as an entailment problem:\n",
        "Does the context logically support every claim made in the answer?\n",
        "\n",
        "Metric:\n",
        "Faithfulness = Number of Claims Supported by Context/Total Claims in Answer\n",
        "\t​\n",
        "Practical Implementation:\n",
        "Use LLM-based evaluators (e.g., RAGAS faithfulness metric).\n",
        "\n",
        "\n",
        "## 3. Hallucination Prevention\n",
        "\n",
        "A combination of design-time safeguards and evaluation checks ensures grounding.\n",
        "\n",
        "(i). Prompt-Level Guardrails\n",
        "Use an explicit instruction such as:\n",
        "“Answer ONLY using the provided context. If the answer is not present, respond with ‘I cannot find this information in the provided text.’”\n",
        "\n",
        "This discourages parametric knowledge usage.\n",
        "\n",
        "(ii). Retrieval Constraints\n",
        "Limit context to top-k high-similarity chunks.\n",
        "Apply a similarity threshold to filter weak matches.\n",
        "Use chunk overlap to avoid loss of meaning.\n",
        "\n",
        "(iii). Citation-Based Generation\n",
        "Require the model to:\n",
        "Quote supporting lines, or\n",
        "Provide passage references.\n",
        "This makes hallucinations easily detectable.\n",
        "\n",
        "(iv). Post-Generation Verification\n",
        "Run a second LLM check:\n",
        "Verification Prompt:\n",
        "“Is every statement in this answer supported by the provided context? Return YES or NO with justification.”\n",
        "Reject or regenerate answers flagged as unsupported.\n",
        "\n",
        "(v). Automated Evaluation with RAGAS\n",
        "RAGAS enables scalable testing without human labeling by measuring:\n",
        "Context Precision\n",
        "Faithfulness\n",
        "Answer Relevance\n",
        "\n",
        "This provides a quantitative reliability score for the pipeline."
      ],
      "metadata": {
        "id": "kwERn4ozz5XS"
      }
    }
  ]
}